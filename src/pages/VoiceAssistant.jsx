import { useNavigate } from '@solidjs/router';
import { createSignal, Show } from 'solid-js';
import { createEvent } from '../supabaseClient';
import { createNotification } from '../components/Notification';

function VoiceAssistant() {
  const navigate = useNavigate();

  const [listening, setListening] = createSignal(false);
  const [transcript, setTranscript] = createSignal('');
  const [assistantResponse, setAssistantResponse] = createSignal('');
  const [loading, setLoading] = createSignal(false);
  const [loadingAudio, setLoadingAudio] = createSignal(false);

  const { NotificationComponent, showNotification } = createNotification();

  let recognition;
  let currentAudio = null; // ูุชุบูุฑ ูุชุฎุฒูู ุงููุงุฆู ุงูุตูุชู ุงูุญุงูู

  const startListening = () => {
    // ุฅููุงู ุฃู ุชุดุบูู ุตูุชู ุณุงุจู
    if (currentAudio) {
      currentAudio.pause();
      currentAudio = null;
    }

    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      alert('ูุชุตูุญู ูุง ูุฏุนู ุงูุชุนุฑู ุนูู ุงูุตูุช.');
      return;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    recognition = new SpeechRecognition();
    recognition.lang = 'ar-EG';
    recognition.continuous = false;

    recognition.onstart = () => {
      setListening(true);
    };

    recognition.onend = () => {
      setListening(false);
    };

    recognition.onresult = (event) => {
      const speechResult = event.results[0][0].transcript;
      setTranscript(speechResult);
      handleAssistantRequest(speechResult);
    };

    recognition.onerror = (event) => {
      console.error('Error during recognition:', event.error);
      setListening(false);
    };

    recognition.start();
  };

  const handleAssistantRequest = async (inputText) => {
    // ุฅููุงู ุฃู ุชุดุบูู ุตูุชู ุณุงุจู
    if (currentAudio) {
      currentAudio.pause();
      currentAudio = null;
    }

    setLoading(true);
    try {
      const result = await createEvent('chatgpt_request', {
        prompt: inputText,
        response_type: 'text',
      });
      setAssistantResponse(result || 'ูู ูุชู ุงูุญุตูู ุนูู ุฑุฏ.');
      await handleSpeakResponse(result || 'ูู ูุชู ุงูุญุตูู ุนูู ุฑุฏ.');
    } catch (error) {
      console.error('Error:', error);
      setAssistantResponse('ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุงูุญุตูู ุนูู ุงูุฑุฏ.');
      showNotification('ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุงูุญุตูู ุนูู ุงูุฑุฏ.', 'error');
    } finally {
      setLoading(false);
    }
  };

  const handleSpeakResponse = async (text) => {
    // ุฅููุงู ุฃู ุชุดุบูู ุตูุชู ุณุงุจู
    if (currentAudio) {
      currentAudio.pause();
      currentAudio = null;
    }

    setLoadingAudio(true);
    try {
      const audioUrl = await createEvent('text_to_speech', {
        text: text,
      });
      // ุชุดุบูู ุงูุตูุช ุงูุฌุฏูุฏ
      currentAudio = new Audio(audioUrl);
      currentAudio.play();
    } catch (error) {
      console.error('ุฎุทุฃ ูู ุชุญููู ุงููุต ุฅูู ููุงู:', error);
      // ูู ุญุงูุฉ ุงูุฎุทุฃุ ูููู ุงุณุชุฎุฏุงู ุชุญููู ุงููุต ุฅูู ููุงู ูู ุงููุชุตูุญ
      if ('speechSynthesis' in window) {
        // ุฅููุงู ุฃู ููุงู ุฌุงุฑู
        window.speechSynthesis.cancel();
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'ar-EG';
        window.speechSynthesis.speak(utterance);
      } else {
        alert('ูุชุตูุญู ูุง ูุฏุนู ุชุญููู ุงููุต ุฅูู ููุงู.');
      }
    } finally {
      setLoadingAudio(false);
    }
  };

  const handleCopyResponse = () => {
    if (assistantResponse()) {
      navigator.clipboard
        .writeText(assistantResponse())
        .then(() => {
          showNotification('ุชู ูุณุฎ ุงูุฑุฏ ุฅูู ุงูุญุงูุธุฉ', 'success');
        })
        .catch((error) => {
          console.error('ูุดู ุงููุณุฎ:', error);
          showNotification('ูุดู ูุณุฎ ุงูุฑุฏ', 'error');
        });
    }
  };

  return (
    <div class="flex flex-col items-center p-4 h-full text-gray-800 pt-8 pb-16">
      <NotificationComponent />
      <button
        onClick={() => navigate(-1)}
        class="self-start mb-4 text-2xl cursor-pointer"
      >
        ๐
      </button>
      <h1 class="text-4xl font-bold text-purple-600 mb-6">ุงููุณุงุนุฏ ุงูุตูุชู</h1>

      <button
        onClick={startListening}
        class={`px-6 py-3 bg-blue-500 text-white rounded-lg hover:bg-blue-600 transition duration-300 ease-in-out transform hover:scale-105 ${
          listening() || loading() ? 'opacity-50 cursor-not-allowed' : 'cursor-pointer'
        }`}
        disabled={listening() || loading()}
      >
        <Show when={!listening()} fallback="ุงุณุชูุน...">
          <Show when={!loading()} fallback="ุฌุงุฑู ุงููุนุงูุฌุฉ...">
            ุงุถุบุท ููุชุญุฏุซ
          </Show>
        </Show>
      </button>

      <Show when={transcript()}>
        <div class="w-full max-w-md mt-6 p-4 bg-white rounded-lg shadow-md">
          <h3 class="text-xl font-bold mb-2 text-purple-600">ูุตู:</h3>
          <p class="text-gray-700 whitespace-pre-wrap mb-4">{transcript()}</p>
        </div>
      </Show>

      <Show when={assistantResponse()}>
        <div class="w-full max-w-md mt-6 p-4 bg-white rounded-lg shadow-md">
          <h3 class="text-xl font-bold mb-2 text-purple-600">ุฑุฏ ุงููุณุงุนุฏ:</h3>
          <p class="text-gray-700 whitespace-pre-wrap mb-4">{assistantResponse()}</p>
          <button
            onClick={handleCopyResponse}
            class="w-full px-4 py-2 bg-green-500 text-white rounded-lg hover:bg-green-600 transition duration-300 ease-in-out transform hover:scale-105 cursor-pointer"
          >
            ูุณุฎ
          </button>
        </div>
      </Show>
    </div>
  );
}

export default VoiceAssistant;